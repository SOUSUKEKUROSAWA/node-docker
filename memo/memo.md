<iframe width="560" height="315" src="https://www.youtube.com/embed/9zUHg7xjIqQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

# Dockerfile
- イメージ作成用の構成ファイル
## `WORKDIR`
- コンテナ内のワーキングディレクトリを定義
- 何かコマンドを実行するときに、このディレクトリからコマンドを実行することになる
- コンテナにファイルをコピーする場合もこのディレクトリ
  - よって，`COPY package.json .`の`.`は`/app`を意味する
## `RUN`
- 基本的に，ローカルで開発するときに打つ必要があるコマンドを指示していくイメージ
## キャッシュ
- Dockerfileは各行が実行される度に，その結果がキャッシュされるため，再利用性が高い
- `COPY . .`で全てのファイルをコピーするにもかかわらず，その前に`COPY package.json .`，`RUN npm install`を実行している理由は，`package.json`があまり変更されないため，時間のかかる`npm install`をソースコードのコピーの先に完了させておくことで，レイヤーを分離して，`npm install`のキャッシュを有効活用できるから（ソースコードの変更があって再度ビルドする場合も，`npm install`のキャッシュはそのまま使える）
## `COPY . .`に関する疑問
- バインドマウントによってローカルのフォルダがコンテナに同期されるのであれば，コピーを作成する必要はないのではないか？
  - 正解：`COPY . .`は必要
    - バインドマウントは開発用で用いているだけで，本番環境では使用しないから
## 環境変数
- `ENV`で設定できる
  - 設定した環境変数を使いたい場合は`$VARIABLE`と書く
- `docker run`コマンドのオプションとして値を受け渡すことも可能だが，複数指定する場合に何個もオプションを付け加えるのは非効率
  - その場合，`.env`に全ての環境変数をまとめるのが効率的
### Tips
- `.env`ファイルにまとめるのは効率的だが，本番環境と開発環境で使い分けをする場合，`ENV`でそれぞれの環境ごとに指定した方が**環境間の結合を生まない**という側面もある
  - これより，環境変数がさほど多くないのであれば，`ENV`による個別指定もよい
# ポートマッピング
- 単に`EXPOSE 3000`とするだけでは，`localhost:3000`にはアクセスできない
  - セキュリティ上，デフォルトではコンテナから外部にはアクセスできるが，外部（windowsなど，localhostのこと）からコンテナにはアクセスできない
  - `docker run`時にポートマッピングを行う必要がある
    - ![](スクリーンショット%202023-03-09%20215139.png)
    - ![](スクリーンショット%202023-03-09%20215340.png)
    - これにより，外部（もしくはlocalhost）からポート3000に来たトラフィックは全てコンテナのポート3000へと送られる
# dockerignoreファイル
## `COPY . .`の問題点と対処法
### 問題点
- ローカルの全てのファイルを`/app`にコピーししまっているため，Dockerfileやmemoディレクトリ，node_modulesディレクトリなど，コンテナに含める必要のないものまでコピーししまっている
  - node_modulesディレクトリは，Dockerfileの中の`COPY package.json`，`RUN npm install`によって自動で生成されるため，コピーを作成するのは無駄（ファイルサイズも大きいため，時間も無駄になる）
  - この他にも環境変数が記述されたファイルなどはコンテナへコピーしない方が良い
### 対処法
- Docker ignore fileを作成し，コピーしたくないファイル名を記述する
  - gitignoreファイルと同じコンセプト
## Tips
- ファイルの指定には正規表現を使用できる
# ボリュームマッピング
- コンテナ内に永続的なデータを持つことができる
- アプリケーションコードのような頻繁に変更が発生するコードを変更するたびにイメージをビルドし直すのは非効率
## バインドマウント
- ボリュームマッピングの一種
- ローカルホストのフォルダとコンテナ内のフォルダを同期できる
- これより，コードが変更されてもコンテナを作成し直す必要がなくなる
### read-only
- バインドマウントにより，ローカルの変更がコンテナに同期されるが，それと同じくコンテナの変更がローカルに同期されてしまう
  - コンテナの変更をローカルに同期したい場合はほとんどない．
  - この場合に便利なのが，***read-onlyなバインドマウント***
    - read-onlyにすることで，コンテナからローカルへの同期は読み取り専用となり，コンテナ内で新たな変更を加えることはできなくなる
### 注意
- ローカルで破壊的な変更を行うと，その変更もコンテナ内の同期されてしまう
  - 例）ローカルで`node_modules`ディレクトリを削除すると，例えDockerfile内の`npm install`で一度，`node_modules`ディレクトリが作成された後でも，それを削除してしまうため，アプリケーションが動作しなくなる
## 匿名ボリューム
- バインドマウントだと全てのローカルの変更内容がコンテナと同期されてしまう
- バインドマウントさせたものの中で，同期したくないものがあった場合は，無名ボリュームとして登録しておくことで，バインドマウントをオーバーライドすることにより，同期を回避することができる
  - ***開発中に，ローカルからは削除したいけどコンテナ内では削除したくないものがある時に使うと便利***
    - バインドマウントにより，Dockerfileやmemoなども同期されてしまうが，これらはローカルから削除する必要がないので，匿名ボリュームに登録する必要もない
      - 本番環境ではバインドマウントは行われないため
### 問題点
- コンテナを再作成する場合，バインドマウントしたボリュームは名前が`/app`と指定されているため，毎回オーバーライドされるが，匿名ボリュームは以前のボリュームを特定できないため，再作成するたびに異なるボリュームが新規作成されてしまう
  - コンテナを作成するたびに容量の消費が大きくなっていってしまう
### 対処法
- コンテナ削除時に関連したボリュームも同時に削除する
### `/app/node_modules`をオーバーライド下にもかかわらず，コンテナ内で`node_modules`ディレクトリが作成されると，ローカルにも同様に`node_modules`ディレクトリが作成される理由
- オーバーライドしたのは`/app/node_modules`の内側．そのため，`node_modules`のフォルダだけは同期され，ローカルにも反映される
  - これは，ローカルの`node_modules`内が空であるのに対し，コンテナ内の`/app/node_modules`内は空ではなく，正常な`node_modules`ディレクトリとなっていることから確認できる
## 名前付きボリューム
- `${volume name}:${path on container}`
- DBコンテナをアプリケーション内で実行している場合，`docker-compose down`時にコンテナが削除されると同時に，DB内のデータも削除されてしまう
- そこで，DB内のデータをボリュームにマッピングしたいが，匿名ボリュームを使用すると，名前による識別ができなくなるため，どのボリュームにDBの内容が入っているかわからなくなってしまう
- よって，ボリュームに名前を付けた名前付きボリュームを使用する
  - 注意
    - 名前付きボリュームは複数のサービスで使用できるため，一つのサービス内で定義するのではなく，`services`と同レベルの`volumes`の中で別途定義する必要がある
# javascript
## オブジェクトのショートハンドプロパティ
- 以下の2パターンの書き方はどちらも同じ出力になる
```js
const user = {
  username: 'JohnDoe'
};
console.log(user)
```
```js
const username = 'JohnDoe'
const user = {
  username
};
console.log(user)
```
## 分割代入（Destructuring assignment）
- オブジェクトや配列の要素を変数に分割して代入することができます。
- 以下の2つのプログラムは同じことを表しています
```js
const person = {
  name: 'John',
  age: 30,
  gender: 'male'
};
const name = person.name;
const age = person.age;
```
```js
const person = {
  name: 'John',
  age: 30,
  gender: 'male'
};
const { name, age } = person;
```
# Node.js
- 変更を反映するにはnodeプロセスをリスタートさせる必要がある
  - ボリュームマッピングを行っていたとしても，コンテナ上では変更が反映されていても，実際には変更が反映されないのはこのため
- ただし，毎回手動でリスタートさせるのは非効率
## 解決策
- nodemonを使用する
## jsにおいてasync/awaitを使用する理由
- jsは一つの処理を終えたら次に処理に移行するシングルスレッド方式を採用している言語
- しかし，js以外の処理（HTTPリクエストやDBアクセス）を行う場合，それらの処理の完了を待たずに次の処理並行してしまう可能性がある
  - https://qiita.com/_takeshi_24/items/1403727efb3fd86f0bcd
### 対処法
- js以外の処理をasync関数でラップし，その処理にawaitをつける
  - こうすることで，非同期処理がプロミスを返すまでjs処理を待機させることができる
- 他にも，コールバック関数を活用して，非同期処理終了後の処理を記述することもできる（こちらの方がシンプルに書けることも多い）
```js
exports.getAllPosts = (req, res) => {

  Post.find((err, doc) => {
    if (err) {
      res.status(400).json({
        status: "fail"
      })
    } else {
      res.status(200).json({
        status: "success",
        results: doc.length,
        data: {
          doc
        }
      })
    }
  })

}
```
## putリクエストとpatchリクエストの違い
- HTTPのPUTリクエストは、リソース全体を更新するために使用されます。PUTリクエストは、サーバー上の既存のリソースを完全に置き換えることを意味します。PUTリクエストを使用する場合、リクエストボディには完全なリソースの表現が含まれる必要があります。
- 一方、HTTP PATCHリクエストは、既存のリソースの一部を更新するために使用されます。PATCHリクエストは、サーバー上の既存のリソースの一部を更新することを意味します。PATCHリクエストを使用する場合、リクエストボディには更新されるプロパティのみが含まれます。
- つまり、PUTリクエストは完全なリソースを置き換えるために使用され、PATCHリクエストは既存のリソースの一部を更新するために使用されます。ただし、これらのリクエストの使用法には、実装による違いがあるため、APIのドキュメントを確認することが重要です。
## APIのエンドポイントを`/api/${version}/${resource}`とすることが推奨される理由
- バージョンを入れる理由
  - APIの変更が発生した場合に、新しいバージョンを別のエンドポイントとして追加することができます。これにより、古いバージョンを利用しているクライアントに影響を与えることなく、並行して，新しいバージョンを追加することができるから
## `app.use(express.json())`が必要な理由
- HTTPリクエストのボディに含まれるJSON形式のデータを、JavaScriptオブジェクトに変換するため
- なぜデフォルトでこの変換を実装していないのか？
  - Node.jsは、HTTPリクエストのボディに含まれるデータがどのような形式であっても、そのまま生のデータとして扱います。これは、Node.jsが汎用的なWebフレームワークであるExpressなどと異なり、HTTPサーバーそのものを提供するために設計されたプラットフォームだからです。
  - 具体的には、Node.jsがHTTPリクエストのボディをJavaScriptオブジェクトに変換することはできません。これは、HTTPリクエストのボディに含まれるデータがJSON形式であっても、XML形式であっても、バイナリデータであっても、そのデータの種類に応じて適切な処理を行うためには、プログラマが明示的にデータの形式を指定する必要があるためです。
  - そのため、Node.jsのHTTPサーバーを使用する場合は、リクエストのボディを扱うためのライブラリやミドルウェアを使用する必要があります。`express.json()`は、JSON形式のデータを扱うための便利なミドルウェアの1つであり、Node.jsアプリケーションにおけるJSONデータの取り扱いを簡単にすることができます。
## jsにおいてtry/catchを使用する理由
- 失敗する可能性のある処理を制御するため（失敗した場合の処理を開発者が定義することができる）
## プロキシサーバの背後でExpressアプリを実行する
- プロキシの背後で Express アプリを実行する場合は、( app.set()を使用して) アプリケーション変数(trust proxy)を設定します。
  - アプリケーション変数が設定されていなくてもアプリの実行に失敗することはありませんが、構成されていない限り、プロキシのIPアドレスがクライアントIPアドレスとして誤って登録されます
  - http://man.hubwiz.com/docset/Express.docset/Contents/Resources/Documents/expressjs.com/guide/behind-proxies.html
- node.js内に`app.enable("trust proxy")`を追記することで，アプリケーションがプロキシサーバを信頼し，リクエストヘッダーから正しいIPアドレスを取得できるようになる
  - 悪意のあるプロキシサーバーは、自分たちがアプリケーションサーバーであるかのようにIPアドレスを偽装することができます。
# nodemon
- コードの変更を監視してくれるパッケージ
- `npm install nodemon --save-dev`でインストール可能
  - `--save-dev`
    - パッケージをローカルインストールするときのオプション
    - これにより，パッケージは`devDependencies`にのみ追加されるようになり，本番環境の`dependencies`と区別することができる
      - 注意
        - 区別はできるが，単に`npm install`をすると`devDependencies`のパッケージもインストールされてしまう．`devDependencies`のインストールを回避するには`npm install --only=production`とする必要がある
          - https://qiita.com/kohecchi/items/092fcbc490a249a2d05c
          - ちなみにnpmのv.3.3.0より前は`--production`と呼ばれていた
            - https://stackoverflow.com/questions/9268259/how-do-you-prevent-install-of-devdependencies-npm-modules-for-node-js-package
- `package.json`内の`scripts`内に，本番環境用の`start`と開発環境用の`dev`を追記することで，開発中はnodemonが変更を監視し，変更があれば自動でnodeプロセスをリスタートしてくれる
  - マウントされたドライブを介してnodemon読み取りを実行するコンテナなどで開発している場合は，`dev`の部分を`nodemon -L index.js`とするといい
    - `-L`
      - レガシーウォッチを意味する．監視を有効にするためのオプション
    - 注意
      - これは見つかった全てのファイルをポーリングする
    - https://github.com/remy/nodemon#application-isnt-restarting
  - `scripts`を作成したので，`Dockerfile`内の`CMD`の部分は`npm run dev`としておく必要がある
## 問題点
- 本番環境の`node_modules`ディレクトリ内に，`--save-dev`でインストールした`devDependencies`用の`nodemon`が存在してしまっている
## 対処法
- Dockerfile内の`RUN npm install`の部分を`RUN npm install --only=producrion`とする
  - これにより，本番環境では`package.json`内の`devDependencies`の部分にあるパッケージを削除して，イメージサイズを抑えることができる
  - この設定を本番環境のみで行うため，**Dockerfile内にscriptを記述する必要がある**
    - Composeファイルから`args`として，Dockerfileの`ARG`へ値を渡す必要がある
# docker-composeファイル
- 複数のコンテナ作成を含めたアプリケーション構築用の構成ファイル
  - Dockerfileの読み込み指示も行える
## なぜ必要か
- 一つのコンテナを作成するにもコマンドは少し長い，さらに，大規模なアプリで複数のコンテナが必要な場合，コマンドを一つずつ打つのは非効率だから
  - Composeファイルを作成すれば，あとは`docker-compose up`コマンド一つで複数のコンテナを作成することができる
## `version`
- Composeファイルのバージョンを指定する
  - https://docs.docker.com/compose/compose-file/compose-versioning/
  - https://zenn.dev/link/comments/8ce9c7a1074312
## インデント
- yamlファイルはインデントが重要
  - レイヤーごとにインデントをそろえないと，正常に動作しない
## `services`
- 一般的にアプリは複数のサービス（コンテナ）から構成されるため，このレイヤーでまとめる
## `build`
### `context`
- Dockerfileの実行
- Dockerfileのパスを指定する
### `args`
- Dockerfileの`ARG`へ受け渡すkey，valueを指定
### イメージ名
- `build`によって作成されたイメージの名前は`${directory on Dockerfile}-${service name}`となる
### コンテナ名
- コンテナ名は`${directory on Dockerfile}-${service name}-${number of container made}`となる
## `ports`
- リスト形式で指定する必要がある
  - ポートは複数設定することができるから
## `enviroment` vs `env_file`
- `enviroment`
  - 環境変数を一つずつ指定できる
- `env_file`
  - 環境ファイルを読み込むことで，環境変数を指定する
## `docker-compose up`によるアプリケーションの再実行の挙動
- 一度アプリケーションを実行すると，2度目以降実行する際は，`build`の部分でイメージのビルドからやり直すわけではない
  - イメージ名は規定があるため，システムが発見できる．イメージ名が既に存在した場合，イメージのリビルドはスキップされ，既存のイメージが参照される
### 問題点
- 上記の自動参照のため，仮にDockerfileを変更したとしても，イメージはリビルドされずに，古い既存のイメージを参照し続けてしまう
### 対処法
- `docker-compose up`コマンドにイメージのリビルドを強制するオプション（`--build`）を付与する
## 本番環境と開発環境の使い分け
- Composeファイルにはボリュームマッピングやポートマッピングの記述があるが，これらは本番環境では必要のないもの．どのように使い分ければいい？
### 対処法
1. Dockerfileを開発環境用と本番環境用に2つ用意する
    - 簡単
2. 一つのDockerfile内に開発環境用と本番環境用の構成を記述する
    - 少しテクニカル（カスタムbashスクリプトなどを用意する必要がある）
      - 例）`CMD`を`["sh", "start.sh"]`のように書き換えて，以下のような`start.sh`を作成する
```bash
:
if [ "$NODE_ENV" = "development" ]
then
  # develop環境の処理
else
  # それ以外の処理
fi
```
3. Dockerfileは一つのままで，Composeファイルを開発環境用と本番環境用に2つ用意する
    - 注意
      - 2つのComposeファイルの親ファイルとして，`docker-compose`ファイルは必要
        - よって，合計3つのComposeファイルが必要になる
        - 親ファイルには，開発環境と本番環境で共通する内容を記述する
          - ***ビューの継承と同じコンセプト（ETC原則）***
      - `docker-compose`時に，本番環境用と開発環境用のどちらのComposeファイルを使用するか指定する必要がある
### 注意
- 本番環境ではソースコードの同期（バインドマウント）がないので，コードに変更がある場合はその都度イメージのリビルドが必要になる
## image
- 自作したイメージではなく，DockerHubからイメージをプルしてコンテナを作成する場合は，`image`を使って定義する
## Composeファイルで複数コンテナを起動する場合，その起動順序が分からない問題
- そのコンテナ同士に依存関係がある場合，起動する順序によってはアプリが正常に起動しない可能性がある
  - 例）node.jsアプリ内でmongoへ接続する場合，node.jsが先に起動してしまうと，mongoに接続できずにアプリがクラッシュする（mongoコンテナを先に起動する必要がある）
### 対処法
- `depends_on`キーを追加する
  - 依存している側のサービスキー内に追加する
  - 値は依存関係にあるサービス名を指定する
    - nodeとmongoの場合，nodeがmongoに依存しているので，nodeキーの下に`depends_on`を指定する
- 注意
  - これは技術的には問題を必ず解決できるわけではありません．
    - `depends_on`キーによって，mongoコンテナが先に起動するだけであって，DBが実際にnodeアプリによるDB接続より先に稼働しているかどうかを保証するものではありません
    - Dockerにはこれを技術的に解決できる手段がない
      - よって，`depends_on`キーの追加はあくまで不完全な対処法
  - これを技術的に解決していると言えるのはmongooseで，  ***mongooseはDBへの接続を30秒間試行し続けます．***（30秒間試行してダメだった場合，初めてエラーをスローする）
    - これにより，たとえnodeアプリが少し先にDB接続を行ったとしても，一度の接続ミスではクラッシュせず，再接続を試みるため，接続に成功していた
    - ただし，***これはmongooseの実装に依存してしまっているため，自作関数を作るというのが現在私たちにできる妥当な対処法***
- DBへの接続をリトライし続ける関数を記述する
  - ソースコード内に`connectWithRetry`メソッドを記述した．これにより，外部の実装に依存することなく，技術的な解決策を提供できたことになる
## 開発環境と本番環境でポート番号を分ける理由
- セキュリティ上の理由
  - 開発環境と本番環境では、セキュリティ上のリスクが異なります。開発環境では、テストや開発のために機密性の低いデータが扱われることがありますが、本番環境では、重要なデータや機密性の高いデータが扱われることがあります。そのため、本番環境では、不正アクセスや攻撃からシステムを保護するため、不必要なポートのオープンを避ける必要があります。
- ポートの競合を避けるため
  - Dockerでは、同じポート番号を複数のコンテナで使用することができます。しかし、開発環境と本番環境で同じポート番号を使用すると、ポートの競合が発生し、正しく動作しない可能性があります。そのため、開発環境と本番環境で異なるポート番号を使用することで、ポートの競合を回避することができます。
# nodeとmongodbのdocker上での接続
## mongoose
- mongodbのライブラリ．DBとの対話をよりやりやすくする
  - https://www.npmjs.com/package/mongoose
# IPアドレス
- コンテナは実行時に自動で分離されたアプリケーション用のネットワークに接続され，IPアドレスが割り当てられる
  - 注意
    - IPアドレスはコンテナ実行の度に変わる可能性があるため，コード内に直接IPアドレスを書くのはNG
  - 対処法
    - DockerにはDNSが用意されており，サービス名を指定すると，そこからそのサービスのIPアドレスを参照してくれる
# config
- 環境変数を扱うディレクトリ
  - コード内にURLなどをハードコーディングしてしまうと，本番環境と開発環境の使い分けがやりにくくなるため，configディレクトリに環境変数をまとめる
  - また，運用方法などが変更した際にもconfigに全て集約されていれば変更しやすくなる
  - さらに，将来的にDockerを使用しなくなった場合などにも対応できる
    - `MONGO_IP: process.env.MONGO_IP || "mongo"`の部分などはDocker上で動かす分には本番環境でも`process.env.MONGO_IP`は必要ない
  - Tips
    - 環境変数を使用する時は，それぞれインポートする必要があるが，vscodeはそれを自動で行ってくれる
# bcrypt.js
- パスワードのハッシュ化を行うためのライブラリ
  - 通常のPOSTリクエストでサインアップを行うとパスワードが平文のまま通信されてしまい危険だから
# セッション
- 認証機能を制御するために用いる，ブラウザにキーとバリューのペアを保持しておかせる仕組み（この形式であればどんな情報でも保持できる）
  - セッションは、ユーザーがWebサイトにログインしたときに生成され、ユーザーがWebサイトにアクセスするたびに使用されます。セッションは、Webサイトによって一意のIDが生成され、ブラウザのクッキーに保存されます。このIDは、サーバー側でセッション情報を管理するために使用されます。セッションを使用することで、ユーザーの認証状態をサーバー側で管理することができます。
  - redisはセッションを保存しておくこともできる
    - この他にも，JSONウェブトークンを利用する方法もありますが，こちらは認証情報をJSONで扱うようなAPI呼び出しによる認証に使用されることが多い
    - maxAgeを設定するとredisへのセッションの保存は一時的なものになり，何ms保持しておくかを定義することができる
      - 通常は数時間または，数日間に設定することが多い
    - セッション内にユーザーの認証情報があればログイン中とみなし，なければログアウトしているとみなす
    - このセッション情報はredisデータベース内に保持されるためブラウザから情報を取得することはできない
## パッケージのインストールバージョンの注意点
- 以下のバージョンでインストールする必要があります
```json
"express": "^4.18.2",
"redis": "^3.1.2"
"connect-redis": "^6.1.3",
"express-session": "^1.17.3",
```
# 認証機能実装の手順
- ログイン時にユーザー名とパスワードをDBに保存する処理を書く
- パスワードをハッシュ化する処理を追加する
- セッション情報をDBへ保持する処理を追加する
- パスワードが認証された際にそのユーザーのセッション情報にユーザー情報を追加する処理を追加する
- リクエストユーザーのセッション情報にユーザー情報が追加されているかをチェックするミドルウェアを追加する
- 認証済みユーザーのみ行えるリクエストにしたいルートにミドルウェアを追加する
# アプリケーションのアーキテクチャ（ロードバランシング）
- Node/Expressアプリはホスト外へポートマッピングを行い，外部との通信を可能にしていたが，mongodbはそれをしていなかった（必要性がなく，開放しない方がセキュリティ上も良いから）
- Nodeアプリをスケールアップしたい場合は，新たにコンテナを作成し，ポートマッピングを行えばよい．
  - 各コンテナのポート番号は一致させる必要がある．これによりロードバランシングを正しく行えるようになる
    - ロードバランシング
      - ネットワーク上でのトラフィックを複数のサーバーに均等に分散する技術のこと
  - ただし，これだとフロントエンド側にいくつのコンテナが稼働しているかという情報を持たせる必要があり，好ましくない
    - そこで，ロードバランサー（nginx）を使用する
      - nginxサーバーがアプリケーションのエントランスとしてふるまう
    - これにより，スケールアップの必要が発生しても複数のポートを開く必要はなくなり，nginxによる単一のポートからアクセスが可能になる
      - nginxのデフォルトポート番号は80

![](スクリーンショット%202023-03-16%20164902.png)
# nginx
- 高性能かつ軽量なWebサーバー/リバースプロキシ
  - 今回は主にロードバランシングを実装するために利用する
  - プロキシサーバ
    - クライアントとサーバの間に入り，リクエスト・レスポンスを中継する
## `default.conf`
- ここにnginxの設定を記述する
- `listen`
  - リッスンするポート番号を指定
- `location`
  - nginxサーバが受け取るリクエストのURLを指定
    - ここを`/api`などに設定しておくと，バックエンドからのリクエストを見分けることができる
  - `proxy_pass`
    - nginxサーバからリクエストを受け渡す先のURL
  - `proxy_set_header`
    - 元のリクエスト送信者のIPを渡すことを確実にするために指定する
## nginxコンテナに設定ファイル（`default.conf`）を取り込む方法
- デフォルトのnginxコンテナに設定ファイルを追加した自作のイメージを作成する
- ボリュームをバインドマウントで構成し，設定ファイルをコンテナ内のファイルと同期させる
  - こっちの方が簡単
# CORS
- Cross-Origin Resource Sharingの略
  - 異なるオリジン（ドメイン、プロトコル、ポート番号）からリクエストされたWebページ上で使用されるリソースについて、ブラウザによるアクセス制限を解除するための仕組み
  - 例）デフォルトでは，フロントエンドが実行されるドメインとバックエンドが実行されるドメインが異なる場合，相互のリクエストは拒否されてしまう．このやり取りを許可するのがCORS
# 本番環境へのデプロイ
## 本番サーバの用意と本番サーバ上でのDocker（docker-compose）の用意
## 環境変数の扱い
- アプリケーションのコードと分離させることが重要
## 本番サーバーへのアプリケーションの移行
- gitへプッシュし，本番サーバーでプルする
- docker composeでアプリケーションを実行
## デプロイ後の変更のプッシュ
- 変更内容をgitへプッシュ
- 本番サーバ上で変更内容をgitからプル
- アプリケーション（イメージ）のリビルド
  - 本番環境ではバインドマウントによるコードの同期およびnodemonによるコード変更の監視は用意していないためリビルドを行う必要がある
  - リビルド時に変更したいファイルは基本的にアプリケーションファイルのみ．DB関連は変更することはほとんどなく，また，簡単に変更できてしまうと大きな障害に発展してしまう可能性もあり，危険
    - そこで，`docker-compose up --build`の後に変更をチェックするサービス名を追加すると，そのサービスの変更のみチェックするようになり安全
      - `docker-compose up --build ${service name}`
    - しかし，これだけだと依存関係のあるサービスもチェックされる（`depends_on`で指定したサービス）
      - 依存関係のあるサービスのチェックが必要ない場合は`--no-deps`オプションを追加する
        - `docker-compose up --build --no-deps ${service name}`
  - コンテナの再作成の強制
    - コードに変更がない場合，`docker-compose up`をしても，コンテナの再作成は行われない（Dockerは変更をチェックして，変更がない場合は何もしないため）．
    - コードに変更がなくてもコンテナを再作成したニーズが発生した場合に使える方法
      - `--force-recreate`オプションを追加する
        - `docker-compose up --force-recreate ${service name}`
      - ただし，ここでも依存関係のあるサービスも一緒に再作成される．それを防ぐためには同様に`--no-deps`オプションを追加する必要がある
        - `docker-compose up --force-recreate --no-deps ${service name}`
## ワークフロー
- 本番環境でイメージのリビルドを行うのはリソースが消費されてしまう（本番サーバのCPUやメモリを消費してしまう）ため好ましくない
  - アプリケーションが大規模になるほどビルドに時間がかかるようになってしまう
  - トラフィックの処理に使うためのリソースが取られてしまう可能性がある
    - ***本番用サーバは本番用トラフィックを処理するためだけにあるべき***
- そこで，本番サーバーではないマシンでイメージを構築できるようなワークフローに移行することが必要

![](スクリーンショット%202023-03-17%20133257.png)
- 開発者がローカル環境でイメージをビルドし，それをDockerHubのようなDockerレジストリにプッシュする
  - `docker-compose build( ${service name})`
  - `docker-compose push( ${service name})`
- そして，本番サーバは新しく作成されたイメージをプルし，コンテナを再作成する
  - `docker-compose pull( ${service name})`
  - `docker-compose up( --no-deps ${service name})`
- つまり，ソースコードを本番環境に受け渡すのではなく，ビルド済みのイメージを受け渡すイメージ

![](スクリーンショット%202023-03-17%20134909.png)
### 自動化
- docker watchtower
  - DockerHub上のアプリケーションで使用しているイメージの変更を監視し，変更があれば自動でプルする
    - このツール自体もコンテナとして作成されている
### オーケストレーション
- ここまでのフローでは，変更の度にコンテナを再作成する必要があった
  - つまり，それまでのトラフィックは再作成の度に削除されてしまっていた
    - ローリングアップデートができない
      - この手法では、新しいバージョンのアプリケーションを徐々に展開し、徐々に古いバージョンのアプリケーションを置き換えます
  - Composeファイルはただ単にコマンドを複数打つ必要をなくすための設定ファイルであり，オーケストレーターではない
    - 一つのサーバー上でしか実行できない
      - 複数のサーバーで実行して，サービスダウンに対する冗長性を持たせたりすることはできない
- そこで．オーケストレーションツールが必要
- Docker Swarm
  - Dockerインストール時点でDocker Swarmも用意されている
    - ただデフォルトでは使用できないようになっているため，設定変更が必要
  - `docker swarm init`でSwarmを利用可能にし，Composeファイル内に設定を書いていくことで利用できる

---

# Command Tips
## `docker image ls`
- イメージ一覧
## `docker image rm ${image id}`
- イメージ削除
## `docker build -t ${image name} ${DIR of Dockerfile}`
- 名前を付けてイメージを作成
## `docker run -d --env-file ${path on local env file} -p ${port on outside-world(ex. localhost)}:${port on container} -v ${path on localhost}:${path on container}:ro -v ${path on container folder you wanna ignore } --name ${container name} ${image name}`
- ポートマッピングとボリュームマッピングを行ったうえで，環境変数を読み込んで，detachモードで名前を付けた，コンテナを作成
  - `-d`
    - デフォルトではコンテナはCLIやコンソールに接続される
    - detachモードではCLIはフリーでオープンのまま
  - `-v`
    - ボリュームマッピングで使用するパスは絶対パスで指定する必要がある
      - 絶対パスは該当するファイル上で`Shift+Alt+C`を打つとコピーできる
      - さらにスピーディーな方法
        - windows command shellの場合
          - `%cd%`
        - windows powershellの場合
          - `${pwd}`
        - macまたはLinuxの場合
          - `$(pwd)`
    - 2つ目の`v`オプションが匿名ボリューム（`path on localhost`は指定しなくてOK）
      - 同期させたくないフォルダのパスを指定する
    - `:ro`
      - 1つ目の`v`オプションの部分のパスの後にある`:ro`が，バインドマウントのread-onlyモードを指定している
  - 環境変数は指定ファイルを読み込むほかにも，`--env ${environmental variable}=${value}`として個別に指定することも可能（ただし，非効率）
## `docker rm ${container name} -f`
- `f`
  - コンテナを停止したうえで削除する
## `docker exec -it ${container name} bash`
- コンテナ実行中にコンテナ内のファイルシステムにアクセスする
  - `docker exec`
    - コンテナ実行中に追加命令を実行する
  - `-it`
    - `i`
      - インタラクティブモード
    - `t`
      - ターミナル実行モード
  - `bash`
    - Dockerfile内の`CMD`を`bash`に上書きする
### `printenv`
- 環境変数を出力する
## `docker logs ${container name}`
- コンテナのログを表示する
  - コンテナが想定外の動作をしたときに使える
- `-f`
  - ログのリアルタイム更新
    - 開発中にこのフラグを付けておくと，***エラーにすぐに気づくことができる***
## `docker volume ls`
- ボリュームの一覧表示
## `docker volume rm ${volume name}`
- ボリュームの削除
## `docker volume prune`
- 未使用のボリュームの一括削除
  - ただ，未使用でも削除しない方がいいボリュームも多い
    - DB用のボリュームなど
## `docker rm ${container name} -fv`
- `v`
  - 関連したボリュームを削除したうえでコンテナを削除する
    - 匿名ボリュームなども削除できる
## `docker-compose up`
- Composeファイルを読み込んでアプリケーションを実行する
  - 注意
    - `-`を忘れないこと！`docker compose`は別のコマンドを指示してしまう
  - `--help`
    - コマンドのヘルプの一覧表示
  - `-d`
    - detachモードで実行
  - `--build`
    - イメージのビルドを強制する 
  - `-f`
    - 別のComposeファイルを指定する
    - 複数このオプションを記述することで，指定したファイルを順に読み込んでいくようにすることも可能
      - 例）`docker-compose -f docker-compose.yml -f docker-compose.dev.yml up`
        - これにより，まずは`docker-compose.yml`を読み込み，次に`docker-compose.dev.yml`を読み込み，差分を追加するように設定される
        - つまり，**ファイルの指定順が重要**
    - 注意
      - `docker-compose down`でコンテナを停止させる時も`-f`は必要
  - `${service name}`
    - Composeファイルの中の指定したサービスのみ実行する
      - ただし，依存関係にあるサービスは実行されてしまう
      - 依存関係にあるサービスも実行したくないという場合は`--no-deps`オプションをサービス名を入力する前に追加する
  - `-V`
    - Composeが再起動されたときに、匿名ボリュームが削除され、新しい匿名ボリュームが作成されます。
      - 古いデータがホストファイルシステムに残らず、容量不足の問題を回避できます。
  - `--scale ${service name}=${number of containers}`
    - 同じコンテナを複数（数を指定）起動する
### 本番環境と開発環境の使い分け
- 開発環境でコンテナを実行したいとき
  - `docker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d --build`
- 本番環境でコンテナを実行したいとき
  - `docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d --build`
### 2度目以降の`docker-compose up`
- すでにアプリケーションが起動している状態で再度`docker-compose up`を行うと，DockerはComposeファイルの変更点を検知し，差分を実行してくれる
  - Composeファイルを変更しただけの場合（イメージのリビルドが必要ない場合），いちいち`docker-compose down`を行ってから，`docker-compose up`を行う必要はない
## `docker-compose down`
- アプリケーションを停止する
  - 注意
    - コンテナは削除される！
      - 再び`docker-compose up`をするとコンテナが再生するわけではなく，全く別のコンテナが新規作成されている
        - よって，DBを担うコンテナをdownさせると，DB内のデータも削除されてしまう
  - `docker-compose down -v`
    - アプリケーションに関連したボリュームの削除
      - 注意
        - 匿名ボリュームだけでなく，名前付きボリュームも削除されてしまう
        - 対処法
          - 一度`docker-compose up`をdetachモードで実行して，コンテナ実行中に`docker volume prune`をすることで，現在のアプリケーションの実行に必要のないボリュームを一括削除することができる
            - これにより，使用中の名前付きボリュームは削除されなくなる
## `mongosh -u "${username}" -p "${password}"`
- mongoアプリケーションの中で，DBに接続する
  - 注意
    - `mongo`シェルはMongoDB 6.0から削除されました．代替は`mongosh`です．
      - https://stackoverflow.com/questions/73582703/mongo-command-not-found-on-mongodb-6-0-docker-container
### Tips
- `docker exec -it ${container name} mongosh -u "${username}" -p "${password}"`
  - DockerCLIから直接mongoshに接続できる
- `docker exec -it ${container name} redis-cli`
  - DockerCLIから直接redis CLIに接続できる
## `db`
- mongodbに接続した状態で，現在接続しているDB名を出力する
  - `pwd`的コマンド
## `use ${db name}`
- `db name`と名前の一致するDBにスイッチする．もし一致するDBがなかった場合，新たに作成する
## `show dbs`
- 現在，存在するDBの一覧表示
  - 注意
    - データが入っていないDBはDBとみなされないため，この一覧には表示されない
## `db.${collection name}.insertOne({${key}: "${value}"})`
- コレクションへの1件のデータの挿入
## `db.${collection name}.find()`
- コレクションないのでデータの全件取得
## `docker inspect ${container name}`
- コンテナの詳細情報の表示
## `docker network ls`
- 現在のネットワーク一覧を表示
## `ping ${IP address}`
- 指定したIPアドレス先にエコー要求メッセージを送信し続ける
  - 通信の確認に用いることができる
- インストール（コンテナ上のbash内）
  - `apt-get update && apt-get install -y iputils-ping`
## `docker network inspect ${network name}`
- ネットワークの詳細情報の表示
## `redis-cli`
- redis CLIに接続する
## `keys *`
- redisDB内の全てのエントリを表示する
## `get ${key}`
- 指定したエントリ（キー）の詳細を表示する
## `docker push ${image name}`
- Dockerレジストリにイメージをプッシュする
  - 注意
    - まずは`docker login`をする必要がある
    - ***イメージ名はDockerHub内で一意でなければならない***ため，一般的には`${registry name}/${image name}`とする
## `docker image tag ${image name} ${another image name}`
- イメージに別名（タグ）を付ける
## `docker-compose build`
- Composeファイルにあるサービスに対してイメージをビルドするが，コンテナは起動しない
  - 新しいイメージをビルドする場合に便利
    - いちいちDockerfileから一つずつイメージをビルドする必要がないから
- `docker-compose build ${service name}`
  - 特定のサービスのイメージのみをビルドする
## `docker-compose push`
- Composeファイルにあるサービスに対してイメージをDockerレジストリにプッシュする
-  `docker-compose push ${service name}`
  - 特定のサービスのイメージのみをプッシュする
## `docker-compose pull`
- Composeファイルに定義された各サービスに対して、そのサービスが使用するDockerイメージを取得します。